import type { ComparisonPage } from "../types";

// ─── Comparisons ────────────────────────────────────────────────────────────
export const comparisons: ComparisonPage[] = [
  {
    slug: "langchain-vs-llamaindex",
    toolASlug: "langchain",
    toolBSlug: "llamaindex",
    seoTitle: "LangChain vs LlamaIndex (2025) — Detailed Comparison",
    seoDescription: "LangChain vs LlamaIndex: which LLM framework is better for your project? Compare features, use cases, performance, and ecosystem support.",
    verdict: "LangChain is better for complex agent systems and diverse LLM workflows. LlamaIndex wins for RAG-focused applications and data-heavy use cases. Many teams use both together.",
    features: [
      { name: "Primary Focus", toolA: "General LLM applications & agents", toolB: "Data indexing & RAG" },
      { name: "Agent Support", toolA: "Comprehensive (LangGraph)", toolB: "Basic agent capabilities" },
      { name: "Data Connectors", toolA: "Moderate", toolB: "Extensive (160+ loaders)" },
      { name: "Learning Curve", toolA: "Steep — many abstractions", toolB: "Moderate — focused API" },
      { name: "Community Size", toolA: "Very large (95K+ stars)", toolB: "Large (37K+ stars)" },
      { name: "Production Readiness", toolA: "High (LangSmith observability)", toolB: "High (LlamaCloud)" },
      { name: "TypeScript Support", toolA: "Full (LangChain.js)", toolB: "Available (TypeScript SDK)" },
      { name: "Streaming Support", toolA: "Built-in", toolB: "Built-in" },
    ],
  },
  {
    slug: "crewai-vs-autogen",
    toolASlug: "crewai",
    toolBSlug: "autogen",
    seoTitle: "CrewAI vs AutoGen (2025) — Multi-Agent Framework Comparison",
    seoDescription: "CrewAI vs AutoGen: which multi-agent framework should you choose? Compare role-based agents, conversation patterns, and production readiness.",
    verdict: "CrewAI is simpler and better for production role-based workflows. AutoGen is more powerful for complex multi-agent conversations and research. Choose CrewAI for speed to production, AutoGen for flexibility.",
    features: [
      { name: "Agent Model", toolA: "Role-based with goals & backstories", toolB: "Conversational agents" },
      { name: "Complexity", toolA: "Low — simple API", toolB: "Medium — flexible but complex" },
      { name: "Task Delegation", toolA: "Sequential & hierarchical", toolB: "Flexible conversation patterns" },
      { name: "Human-in-the-Loop", toolA: "Supported", toolB: "First-class support" },
      { name: "Code Execution", toolA: "Via tools", toolB: "Built-in Docker sandbox" },
      { name: "Framework Integration", toolA: "Built on LangChain", toolB: "Standalone" },
      { name: "Enterprise Support", toolA: "Growing", toolB: "Microsoft-backed" },
      { name: "Documentation", toolA: "Good", toolB: "Comprehensive" },
    ],
  },
  {
    slug: "pinecone-vs-weaviate",
    toolASlug: "pinecone",
    toolBSlug: "weaviate",
    seoTitle: "Pinecone vs Weaviate (2025) — Vector Database Comparison",
    seoDescription: "Pinecone vs Weaviate: which vector database is right for you? Compare managed vs open-source, performance, pricing, and features.",
    verdict: "Pinecone is best for teams wanting fully managed simplicity with no ops overhead. Weaviate wins for teams needing open-source flexibility, hybrid search, and self-hosting control.",
    features: [
      { name: "Deployment", toolA: "Fully managed only", toolB: "Self-hosted or managed cloud" },
      { name: "Open Source", toolA: "No", toolB: "Yes (BSD-3)" },
      { name: "Hybrid Search", toolA: "Vector only", toolB: "Vector + keyword (BM25)" },
      { name: "Built-in Vectorizers", toolA: "No — bring your own", toolB: "Yes — multiple modules" },
      { name: "Pricing", toolA: "Free tier, then $70+/mo", toolB: "Free self-hosted, cloud starts free" },
      { name: "Scalability", toolA: "Serverless auto-scaling", toolB: "Horizontal scaling" },
      { name: "Query Performance", toolA: "Excellent", toolB: "Very good" },
      { name: "Ecosystem", toolA: "Extensive integrations", toolB: "Good integrations" },
    ],
  },
  {
    slug: "langchain-vs-crewai",
    toolASlug: "langchain",
    toolBSlug: "crewai",
    seoTitle: "LangChain vs CrewAI (2025) — Agent Framework Comparison",
    seoDescription: "LangChain vs CrewAI: compare the leading agent frameworks. LangChain's flexibility vs CrewAI's simplicity for multi-agent systems.",
    verdict: "LangChain is a comprehensive LLM framework with agent capabilities. CrewAI is purpose-built for multi-agent orchestration. Use LangChain for general LLM apps, CrewAI for dedicated multi-agent workflows (it uses LangChain under the hood).",
    features: [
      { name: "Scope", toolA: "Full LLM application framework", toolB: "Multi-agent orchestration" },
      { name: "Agent Design", toolA: "Flexible agent types", toolB: "Role-based with personality" },
      { name: "Learning Curve", toolA: "Steep", toolB: "Gentle" },
      { name: "Use Case Breadth", toolA: "RAG, chains, agents, tools", toolB: "Multi-agent workflows" },
      { name: "Setup Time", toolA: "Hours for complex setups", toolB: "Minutes to first agent crew" },
      { name: "Community", toolA: "95K+ GitHub stars", toolB: "25K+ GitHub stars" },
      { name: "Production Tooling", toolA: "LangSmith, LangServe", toolB: "Basic monitoring" },
      { name: "Extensibility", toolA: "Highly extensible", toolB: "Moderate" },
    ],
  },
  {
    slug: "autogpt-vs-metagpt",
    toolASlug: "autogpt",
    toolBSlug: "metagpt",
    seoTitle: "AutoGPT vs MetaGPT (2025) — Autonomous Agent Comparison",
    seoDescription: "AutoGPT vs MetaGPT: compare autonomous AI agents. General-purpose autonomy vs structured software development agent teams.",
    verdict: "AutoGPT is better for general-purpose autonomous tasks with its plugin ecosystem. MetaGPT excels at structured software development with its company-simulation approach. Choose based on your use case.",
    features: [
      { name: "Focus", toolA: "General-purpose autonomy", toolB: "Software development" },
      { name: "Agent Structure", toolA: "Single agent with tools", toolB: "Multi-agent company simulation" },
      { name: "Output Type", toolA: "Task completions", toolB: "Full software artifacts" },
      { name: "Plugin System", toolA: "Extensive marketplace", toolB: "Limited" },
      { name: "Token Efficiency", toolA: "High consumption", toolB: "Moderate" },
      { name: "Community", toolA: "168K+ stars (largest)", toolB: "45K+ stars" },
      { name: "Customization", toolA: "High via plugins", toolB: "Moderate via roles" },
      { name: "Reliability", toolA: "Can loop/stall", toolB: "More structured execution" },
    ],
  },

  // ─── New comparisons (plan) ─────────────────────────────────────────────────
  {
    slug: "langgraph-vs-langchain",
    toolASlug: "langgraph",
    toolBSlug: "langchain",
    seoTitle: "LangGraph vs LangChain (2025) — Agent Framework Comparison",
    seoDescription: "LangGraph vs LangChain: when to use the graph-based agent library vs the full LLM framework. Compare state management, complexity, and use cases.",
    verdict: "LangGraph extends LangChain with graph-based control flow and explicit state—ideal for complex, stateful agents. Use LangChain for general LLM apps and chains; add LangGraph when you need cycles, human-in-the-loop, or multi-actor workflows.",
    features: [
      { name: "Scope", toolA: "Stateful agent graphs (extends LangChain)", toolB: "Full LLM framework (chains, agents, RAG)" },
      { name: "Control Flow", toolA: "Graph-based with cycles", toolB: "Linear chains or agent loops" },
      { name: "State Management", toolA: "Explicit, first-class", toolB: "Implicit in memory/callbacks" },
      { name: "Dependency", toolA: "Built on LangChain", toolB: "Standalone" },
      { name: "Learning Curve", toolA: "Steep — requires LangChain knowledge", toolB: "Steep — many abstractions" },
      { name: "Best For", toolA: "Complex agent workflows, human-in-the-loop", toolB: "RAG, chatbots, broad LLM apps" },
      { name: "Community", toolA: "8K+ stars, growing", toolB: "95K+ stars, very large" },
      { name: "Observability", toolA: "LangSmith integration", toolB: "LangSmith, LangServe" },
    ],
  },
  {
    slug: "chromadb-vs-pinecone",
    toolASlug: "chromadb",
    toolBSlug: "pinecone",
    seoTitle: "ChromaDB vs Pinecone (2025) — Vector Database Comparison",
    seoDescription: "ChromaDB vs Pinecone: compare the open-source embedding database with the managed vector DB. Prototyping, simplicity, and scale.",
    verdict: "ChromaDB is best for prototyping and simple in-process or single-server setups with a dead-simple API. Pinecone wins for production scale, serverless management, and teams that want zero ops. Choose Chroma for speed to prototype, Pinecone for production at scale.",
    features: [
      { name: "Deployment", toolA: "In-process or server, self-hosted", toolB: "Fully managed only" },
      { name: "Open Source", toolA: "Yes", toolB: "No" },
      { name: "Setup", toolA: "Very low — minimal config", toolB: "Low — managed" },
      { name: "Scale", toolA: "Good for small/medium", toolB: "Serverless auto-scaling" },
      { name: "Filtering", toolA: "Limited", toolB: "Metadata filtering, namespaces" },
      { name: "Pricing", toolA: "Free (self-hosted)", toolB: "Free tier, then $70+/mo" },
      { name: "Ecosystem", toolA: "LangChain, LlamaIndex", toolB: "Extensive integrations" },
      { name: "Best For", toolA: "Prototyping, dev experience", toolB: "Production, no-ops teams" },
    ],
  },
  {
    slug: "continue-vs-cody",
    toolASlug: "continue",
    toolBSlug: "cody",
    seoTitle: "Continue vs Cody (2025) — AI Code Assistant Comparison",
    seoDescription: "Continue vs Cody: compare open-source and Sourcegraph-powered AI code assistants. IDE integration, model choice, and codebase context.",
    verdict: "Continue is best for developers who want full control over models (including local) and a single open-source assistant across IDEs. Cody excels when you use Sourcegraph and need deep codebase context and enterprise features. Both support VS Code and JetBrains.",
    features: [
      { name: "Model Choice", toolA: "Any LLM (OpenAI, Anthropic, local, etc.)", toolB: "Cody models + bring-your-own" },
      { name: "Codebase Context", toolA: "Full context awareness in IDE", toolB: "Sourcegraph code graph — very deep" },
      { name: "Open Source", toolA: "Yes", toolB: "Freemium (Pro/Enterprise paid)" },
      { name: "IDEs", toolA: "VS Code, JetBrains", toolB: "VS Code, JetBrains, Neovim" },
      { name: "Pricing", toolA: "Free (you pay for API/local)", toolB: "Free tier, Pro $9/mo" },
      { name: "Enterprise", toolA: "Self-host, customize", toolB: "Enterprise-ready, Sourcegraph integration" },
      { name: "Setup", toolA: "Low; local models can be complex", toolB: "Low; best with Sourcegraph" },
      { name: "Best For", toolA: "Flexibility, local models, OSS", toolB: "Large codebases, enterprise" },
    ],
  },
  {
    slug: "openai-platform-vs-anthropic",
    toolASlug: "openai-platform",
    toolBSlug: "anthropic",
    seoTitle: "OpenAI Platform vs Anthropic (Claude) (2025) — LLM Provider Comparison",
    seoDescription: "OpenAI Platform vs Anthropic: compare the leading AI API providers. GPT-4 vs Claude, ecosystem, pricing, and use cases.",
    verdict: "OpenAI offers the broadest model lineup and ecosystem; Anthropic leads on coding, long context, and safety-focused tooling like MCP. Use OpenAI for maximum compatibility and model choice; choose Anthropic for coding-heavy apps and large-context workflows.",
    features: [
      { name: "Flagship Models", toolA: "GPT-4, GPT-4 Turbo", toolB: "Claude 3, Opus, Sonnet" },
      { name: "Context Window", toolA: "128K (varies by model)", toolB: "200K tokens" },
      { name: "Coding", toolA: "Strong", toolB: "Best-in-class" },
      { name: "Image", toolA: "DALL-E, vision models", toolB: "Limited image generation" },
      { name: "Ecosystem", toolA: "Largest", toolB: "MCP, growing" },
      { name: "Pricing", toolA: "Pay per token", toolB: "Pay per token, premium" },
      { name: "Assistants API", toolA: "Yes (tools, retrieval)", toolB: "Tool use, no built-in Assistants" },
      { name: "Best For", toolA: "Broad use, image, ecosystem", toolB: "Coding, long context, MCP" },
    ],
  },
  {
    slug: "replicate-vs-modal",
    toolASlug: "replicate",
    toolBSlug: "modal",
    seoTitle: "Replicate vs Modal (2025) — ML Infrastructure Comparison",
    seoDescription: "Replicate vs Modal: compare model-serving API with serverless ML compute. Run pre-built models vs run your own code on GPUs.",
    verdict: "Replicate is best when you want to run thousands of pre-built models with a simple API and no infrastructure. Modal is best when you need to run custom code, GPU workloads, or full control over your ML pipeline. Use Replicate for inference-as-a-service; use Modal for custom compute.",
    features: [
      { name: "Model", toolA: "Pre-built models (Cog), simple API", toolB: "Your code, any framework" },
      { name: "GPU", toolA: "Managed per prediction", toolB: "Direct GPU access, serverless" },
      { name: "Customization", toolA: "Limited — use existing models", toolB: "Full — any Python/ML code" },
      { name: "Pricing", toolA: "Pay per prediction", toolB: "Pay per compute second" },
      { name: "Cold Starts", toolA: "Can be noticeable", toolB: "Fast cold starts" },
      { name: "Use Case", toolA: "Image gen, audio, inference", toolB: "Training, serving, data pipelines" },
      { name: "Setup", toolA: "Low", toolB: "Low" },
      { name: "Best For", toolA: "Quick model tryout, no ops", toolB: "Custom ML workloads, control" },
    ],
  },
  {
    slug: "swe-agent-vs-devin",
    toolASlug: "swe-agent",
    toolBSlug: "devin",
    seoTitle: "SWE-agent vs Devin (2025) — AI Coding Agent Comparison",
    seoDescription: "SWE-agent vs Devin: compare open-source GitHub-issue agent with autonomous commercial software engineer. Bug fixing vs full-stack development.",
    verdict: "SWE-agent is best for automated, benchmark-grade GitHub issue fixing with open-source control and your choice of LLM. Devin is best for full autonomous development with its own environment and broad task coverage—at a premium price. Choose SWE-agent for focused, reproducible fixes; Devin for end-to-end autonomous engineering.",
    features: [
      { name: "Focus", toolA: "GitHub issue resolution, bug fixes", toolB: "Full-stack development, deploy" },
      { name: "Open Source", toolA: "Yes", toolB: "No" },
      { name: "Environment", toolA: "Custom computer interface", toolB: "Own shell, editor, browser" },
      { name: "Benchmark", toolA: "State-of-the-art on SWE-bench", toolB: "Proprietary" },
      { name: "Pricing", toolA: "Free (you pay for LLM)", toolB: "$500/mo" },
      { name: "Task Scope", toolA: "Narrow — code fixes", toolB: "Broad — plan, code, debug, deploy" },
      { name: "Setup", toolA: "High", toolB: "Low" },
      { name: "Best For", toolA: "CI/automated fixes, research", toolB: "Hands-off autonomous dev" },
    ],
  },
];
