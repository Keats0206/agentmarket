import type { Tool } from "../types";

// ─── Tools ──────────────────────────────────────────────────────────────────
export const tools: Tool[] = [
  // ── Agents ────────────────────────────────────────────────────────────────
  {
    slug: "autogpt",
    name: "AutoGPT",
    shortDescription: "Autonomous AI agent that chains LLM calls to accomplish goals",
    description: "AutoGPT is an open-source autonomous AI agent that leverages GPT-4 to break down goals into sub-tasks, execute them, and iterate. It pioneered the autonomous agent paradigm and supports plugins, web browsing, code execution, and long-term memory via vector stores.",
    category: "agent",
    subcategories: ["autonomous", "general-purpose"],
    useCases: ["Task automation", "Research & analysis", "Content generation"],
    integrations: ["OpenAI", "Pinecone", "Redis", "Docker"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/Significant-Gravitas/AutoGPT",
    githubStars: 168000,
    websiteUrl: "https://agpt.co",
    docsUrl: "https://docs.agpt.co",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Massive community & plugin ecosystem", "Fully autonomous execution", "Extensible architecture"],
    cons: ["High token consumption", "Can loop on complex tasks", "Requires careful prompt engineering"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "crewai",
    name: "CrewAI",
    shortDescription: "Framework for orchestrating role-playing autonomous AI agents",
    description: "CrewAI enables you to create AI agents with specific roles, goals, and backstories that collaborate to accomplish complex tasks. It emphasizes simplicity and production-readiness, with built-in support for sequential and hierarchical task delegation.",
    category: "agent",
    subcategories: ["multi-agent", "orchestration"],
    useCases: ["Multi-agent workflows", "Content pipelines", "Research automation"],
    integrations: ["LangChain", "OpenAI", "Anthropic", "Google AI"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/crewAIInc/crewAI",
    githubStars: 25000,
    websiteUrl: "https://crewai.com",
    docsUrl: "https://docs.crewai.com",
    featured: true,
    sponsoredTier: "category",
    lastUpdated: "2025-02-12",
    pros: ["Simple role-based agent design", "Production-ready", "Great LangChain integration"],
    cons: ["Younger ecosystem than LangChain", "Limited built-in tools", "Sequential execution can be slow"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "autogen",
    name: "AutoGen",
    shortDescription: "Microsoft's framework for building multi-agent conversational systems",
    description: "AutoGen by Microsoft Research enables building LLM applications via multi-agent conversations. Agents can be customized to use LLMs, human inputs, and tools. Supports complex conversation patterns including group chat, nested conversations, and teachable agents.",
    category: "agent",
    subcategories: ["multi-agent", "conversational"],
    useCases: ["Conversational AI systems", "Code generation", "Mathematical reasoning"],
    integrations: ["OpenAI", "Azure", "HuggingFace", "Local LLMs"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/microsoft/autogen",
    githubStars: 35000,
    websiteUrl: "https://microsoft.github.io/autogen/",
    docsUrl: "https://microsoft.github.io/autogen/docs/Getting-Started",
    featured: false,
    lastUpdated: "2025-02-08",
    pros: ["Backed by Microsoft Research", "Flexible conversation patterns", "Strong code execution support"],
    cons: ["Steeper learning curve", "Complex configuration", "Heavy dependency tree"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "metagpt",
    name: "MetaGPT",
    shortDescription: "Multi-agent framework that simulates a software company",
    description: "MetaGPT assigns different roles to GPTs to form a collaborative software entity. Given a one-line requirement, it outputs user stories, competitive analysis, requirements, data structures, APIs, and full code. It mimics the structure of a real software company.",
    category: "agent",
    subcategories: ["multi-agent", "software-engineering"],
    useCases: ["Software development", "Project planning", "Code architecture"],
    integrations: ["OpenAI", "Anthropic", "Mermaid"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/geekan/MetaGPT",
    githubStars: 45000,
    websiteUrl: "https://www.deepwisdom.ai",
    featured: false,
    lastUpdated: "2025-01-20",
    pros: ["End-to-end software generation", "Structured output artifacts", "Novel SOPs for agents"],
    cons: ["High token costs for full runs", "Output quality varies", "Limited to software domain"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "swe-agent",
    name: "SWE-agent",
    shortDescription: "AI agent that autonomously fixes GitHub issues",
    description: "SWE-agent by Princeton NLP turns LLMs into software engineering agents that can fix real GitHub issues. It provides a custom computer interface for the LLM to browse repositories, edit files, and run tests, achieving state-of-the-art performance on the SWE-bench benchmark.",
    category: "agent",
    subcategories: ["coding", "software-engineering"],
    useCases: ["Bug fixing", "GitHub issue resolution", "Code maintenance"],
    integrations: ["GitHub", "OpenAI", "Anthropic", "Docker"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/princeton-nlp/SWE-agent",
    githubStars: 14000,
    websiteUrl: "https://swe-agent.com",
    featured: false,
    lastUpdated: "2025-02-05",
    pros: ["State-of-the-art on SWE-bench", "Real-world GitHub integration", "Automated testing"],
    cons: ["Compute intensive", "Best with GPT-4/Claude", "Narrow focus on code fixes"],
    setupComplexity: "High",
    maturity: "Early",
  },
  {
    slug: "aider",
    name: "Aider",
    shortDescription: "AI pair programmer in your terminal",
    description: "Aider is a command-line AI pair programming tool that lets you edit code in your local git repo with LLMs. It works with GPT-4, Claude, and other models. Aider automatically commits changes, handles multi-file edits, and understands your entire codebase via repo maps.",
    category: "agent",
    subcategories: ["coding", "pair-programming"],
    useCases: ["Code editing", "Refactoring", "Feature development"],
    integrations: ["Git", "OpenAI", "Anthropic", "Ollama", "VS Code"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/paul-gauthier/aider",
    githubStars: 22000,
    websiteUrl: "https://aider.chat",
    docsUrl: "https://aider.chat/docs",
    featured: true,
    sponsoredTier: "basic",
    lastUpdated: "2025-02-11",
    pros: ["Excellent git integration", "Multi-file editing", "Works with many LLMs"],
    cons: ["Terminal-only interface", "Token costs can add up", "Learning curve for complex edits"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "devin",
    name: "Devin",
    shortDescription: "Autonomous AI software engineer by Cognition Labs",
    description: "Devin is an autonomous AI software engineer that can plan, write, debug, and deploy code. It has its own shell, code editor, and browser, allowing it to handle complex engineering tasks end-to-end. It can learn new technologies, build and deploy apps, and find & fix bugs.",
    category: "agent",
    subcategories: ["coding", "autonomous"],
    useCases: ["Full-stack development", "Bug fixing", "Codebase learning"],
    integrations: ["GitHub", "Slack", "Various cloud platforms"],
    pricingModel: "Paid",
    pricing: "$500/mo",
    websiteUrl: "https://devin.ai",
    featured: false,
    lastUpdated: "2025-02-01",
    pros: ["Full autonomous development", "Own sandboxed environment", "Handles complex tasks"],
    cons: ["Expensive", "Closed source", "Can be slow on large tasks"],
    setupComplexity: "Low",
    maturity: "Early",
  },
  {
    slug: "gpt-engineer",
    name: "GPT Engineer",
    shortDescription: "Generate entire codebases from a single prompt",
    description: "GPT Engineer takes a natural language prompt and generates an entire codebase. It asks clarifying questions, generates code, and allows iterative refinement. Designed to be easy to adapt and extend, with a focus on developer experience.",
    category: "agent",
    subcategories: ["coding", "code-generation"],
    useCases: ["Rapid prototyping", "MVP generation", "Code scaffolding"],
    integrations: ["OpenAI", "Anthropic"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/gpt-engineer-org/gpt-engineer",
    githubStars: 52000,
    websiteUrl: "https://gptengineer.app",
    featured: false,
    lastUpdated: "2025-01-15",
    pros: ["One-prompt codebase generation", "Iterative refinement", "Simple to use"],
    cons: ["Output quality varies", "Limited to initial generation", "Less suited for existing codebases"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "sweep",
    name: "Sweep",
    shortDescription: "AI-powered junior developer that handles tickets",
    description: "Sweep turns GitHub issues into pull requests automatically. It reads your codebase, plans changes, writes code, and handles code review feedback. Designed to handle small to medium tickets that a junior developer would typically handle.",
    category: "agent",
    subcategories: ["coding", "devops"],
    useCases: ["Ticket automation", "PR generation", "Code review response"],
    integrations: ["GitHub", "Linear", "Jira"],
    pricingModel: "Freemium",
    githubUrl: "https://github.com/sweepai/sweep",
    githubStars: 7500,
    websiteUrl: "https://sweep.dev",
    featured: false,
    lastUpdated: "2025-01-28",
    pros: ["Direct GitHub integration", "Handles full PR lifecycle", "Learns from feedback"],
    cons: ["Limited to smaller changes", "Can struggle with complex logic", "Requires well-written issues"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "superagi",
    name: "SuperAGI",
    shortDescription: "Open-source autonomous agent framework with GUI",
    description: "SuperAGI is a dev-first open-source autonomous AI agent framework that enables developers to build, manage and run useful autonomous agents. It provides a GUI for agent management, concurrent agent execution, and a marketplace for tools and agent templates.",
    category: "agent",
    subcategories: ["autonomous", "framework"],
    useCases: ["Agent management", "Workflow automation", "Multi-agent systems"],
    integrations: ["OpenAI", "Google AI", "Pinecone", "S3"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/TransformerOptimus/SuperAGI",
    githubStars: 15000,
    websiteUrl: "https://superagi.com",
    featured: false,
    lastUpdated: "2025-01-10",
    pros: ["Built-in GUI dashboard", "Agent marketplace", "Concurrent execution"],
    cons: ["Heavy setup requirements", "Documentation gaps", "Smaller community"],
    setupComplexity: "High",
    maturity: "Early",
  },
  {
    slug: "continue",
    name: "Continue",
    shortDescription: "Open-source AI code assistant for VS Code and JetBrains",
    description: "Continue is the leading open-source AI code assistant. It connects any model to any IDE, providing autocomplete, chat, and edit capabilities. Supports local models, custom slash commands, and full context awareness of your codebase.",
    category: "agent",
    subcategories: ["coding", "ide-assistant"],
    useCases: ["Code completion", "In-IDE chat", "Code refactoring"],
    integrations: ["VS Code", "JetBrains", "Ollama", "OpenAI", "Anthropic"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/continuedev/continue",
    githubStars: 19000,
    websiteUrl: "https://continue.dev",
    docsUrl: "https://docs.continue.dev",
    featured: false,
    lastUpdated: "2025-02-09",
    pros: ["IDE-native experience", "Works with any LLM", "Fully customizable"],
    cons: ["Setup for local models can be complex", "Extension performance varies", "Context window limits"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "cody",
    name: "Cody",
    shortDescription: "AI coding assistant by Sourcegraph with full codebase context",
    description: "Cody by Sourcegraph is an AI coding assistant that uses the full context of your codebase to answer questions, write code, and automate workflows. Powered by Sourcegraph's code graph, it provides accurate answers grounded in your actual code.",
    category: "agent",
    subcategories: ["coding", "ide-assistant"],
    useCases: ["Code Q&A", "Code generation", "Documentation"],
    integrations: ["VS Code", "JetBrains", "Neovim", "Sourcegraph"],
    pricingModel: "Freemium",
    pricing: "Free tier, Pro $9/mo, Enterprise custom",
    websiteUrl: "https://sourcegraph.com/cody",
    docsUrl: "https://sourcegraph.com/docs/cody",
    featured: false,
    lastUpdated: "2025-02-06",
    pros: ["Full codebase context via Sourcegraph", "Multi-IDE support", "Enterprise-ready"],
    cons: ["Best with Sourcegraph instance", "Free tier limitations", "Can be slow on large repos"],
    setupComplexity: "Low",
    maturity: "Mature",
  },

  // ── Frameworks ────────────────────────────────────────────────────────────
  {
    slug: "langchain",
    name: "LangChain",
    shortDescription: "The most popular framework for building LLM-powered applications",
    description: "LangChain is a framework for developing applications powered by language models. It provides modular components for chains, agents, retrieval, memory, and callbacks. With LangSmith for observability and LangServe for deployment, it's a comprehensive LLM development platform.",
    category: "framework",
    subcategories: ["llm-framework", "agent-framework"],
    useCases: ["RAG applications", "Chatbots", "Agent systems", "Data analysis"],
    integrations: ["OpenAI", "Anthropic", "HuggingFace", "Pinecone", "Weaviate", "ChromaDB"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/langchain-ai/langchain",
    githubStars: 95000,
    websiteUrl: "https://langchain.com",
    docsUrl: "https://python.langchain.com",
    featured: true,
    sponsoredTier: "premium",
    lastUpdated: "2025-02-12",
    pros: ["Massive ecosystem & integrations", "Comprehensive documentation", "Active community"],
    cons: ["Heavy abstraction layer", "Breaking changes between versions", "Can be overkill for simple use cases"],
    setupComplexity: "Medium",
    maturity: "Mature",
  },
  {
    slug: "llamaindex",
    name: "LlamaIndex",
    shortDescription: "Data framework for connecting custom data sources to LLMs",
    description: "LlamaIndex (formerly GPT Index) is a data framework for LLM applications. It excels at ingesting, structuring, and accessing private or domain-specific data. Provides data connectors, indices, query engines, and agents optimized for RAG use cases.",
    category: "framework",
    subcategories: ["llm-framework", "data-framework"],
    useCases: ["RAG applications", "Document Q&A", "Knowledge bases", "Data analysis"],
    integrations: ["OpenAI", "Anthropic", "ChromaDB", "Pinecone", "Weaviate", "PostgreSQL"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/run-llama/llama_index",
    githubStars: 37000,
    websiteUrl: "https://llamaindex.ai",
    docsUrl: "https://docs.llamaindex.ai",
    featured: false,
    lastUpdated: "2025-02-11",
    pros: ["Best-in-class data ingestion", "Excellent RAG capabilities", "Clean API design"],
    cons: ["Less flexible for non-RAG use cases", "Smaller agent ecosystem", "Python-first"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "langgraph",
    name: "LangGraph",
    shortDescription: "Build stateful, multi-actor applications with LLMs",
    description: "LangGraph is a library by LangChain for building stateful, multi-step LLM applications as graphs. It adds cycles, controllability, and persistence to LangChain. Ideal for building complex agent architectures with explicit state management and human-in-the-loop patterns.",
    category: "framework",
    subcategories: ["agent-framework", "orchestration"],
    useCases: ["Complex agent workflows", "Stateful conversations", "Human-in-the-loop systems"],
    integrations: ["LangChain", "OpenAI", "Anthropic", "LangSmith"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/langchain-ai/langgraph",
    githubStars: 8000,
    websiteUrl: "https://langchain-ai.github.io/langgraph/",
    docsUrl: "https://langchain-ai.github.io/langgraph/",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Explicit state management", "Graph-based control flow", "Great for complex agents"],
    cons: ["Requires LangChain knowledge", "Steep learning curve", "New and evolving API"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "semantic-kernel",
    name: "Semantic Kernel",
    shortDescription: "Microsoft's SDK for integrating AI into applications",
    description: "Semantic Kernel is Microsoft's open-source SDK for building AI agents and integrating LLMs into applications. It supports C#, Python, and Java, with features like planners, plugins, memory, and connectors. Designed for enterprise use with Azure OpenAI integration.",
    category: "framework",
    subcategories: ["llm-framework", "enterprise"],
    useCases: ["Enterprise AI apps", "Azure integration", ".NET AI development"],
    integrations: ["Azure OpenAI", "OpenAI", "HuggingFace", "Microsoft Graph"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/microsoft/semantic-kernel",
    githubStars: 22000,
    websiteUrl: "https://learn.microsoft.com/semantic-kernel/",
    docsUrl: "https://learn.microsoft.com/semantic-kernel/",
    featured: false,
    lastUpdated: "2025-02-07",
    pros: ["Enterprise-grade from Microsoft", "Multi-language support", "Strong Azure integration"],
    cons: ["Enterprise-focused complexity", "Smaller community than LangChain", "Microsoft ecosystem bias"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "haystack",
    name: "Haystack",
    shortDescription: "End-to-end NLP framework by deepset for building AI applications",
    description: "Haystack by deepset is an open-source framework for building production-ready LLM applications, RAG pipelines, and search systems. It provides a modular pipeline architecture with components for retrieval, generation, evaluation, and deployment.",
    category: "framework",
    subcategories: ["llm-framework", "search"],
    useCases: ["Search systems", "RAG pipelines", "Document processing"],
    integrations: ["OpenAI", "Anthropic", "Elasticsearch", "Weaviate", "Pinecone"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/deepset-ai/haystack",
    githubStars: 17000,
    websiteUrl: "https://haystack.deepset.ai",
    docsUrl: "https://docs.haystack.deepset.ai",
    featured: false,
    lastUpdated: "2025-02-04",
    pros: ["Production-ready pipelines", "Great search capabilities", "Modular architecture"],
    cons: ["Less agent-focused", "Smaller community", "Documentation can lag behind"],
    setupComplexity: "Medium",
    maturity: "Mature",
  },
  {
    slug: "vercel-ai-sdk",
    name: "Vercel AI SDK",
    shortDescription: "TypeScript toolkit for building AI-powered web applications",
    description: "The Vercel AI SDK is a TypeScript library for building AI-powered streaming UIs and applications. It provides React hooks, streaming utilities, and provider integrations that make it easy to add AI features to Next.js, Nuxt, and SvelteKit apps.",
    category: "framework",
    subcategories: ["web-framework", "streaming"],
    useCases: ["AI chatbots", "Streaming UIs", "Next.js AI apps"],
    integrations: ["OpenAI", "Anthropic", "Google AI", "Mistral", "Vercel"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/vercel/ai",
    githubStars: 10000,
    websiteUrl: "https://sdk.vercel.ai",
    docsUrl: "https://sdk.vercel.ai/docs",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["First-class streaming support", "React/Next.js native", "Multi-provider"],
    cons: ["TypeScript/JavaScript only", "Web-focused", "Vercel ecosystem alignment"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "dspy",
    name: "DSPy",
    shortDescription: "Programming framework for optimizing LLM prompts and weights",
    description: "DSPy by Stanford NLP provides a programming model for building LLM applications by replacing prompting with programming. It automatically optimizes prompts and weights through compilation, making LLM applications more systematic and reproducible.",
    category: "framework",
    subcategories: ["llm-framework", "optimization"],
    useCases: ["Prompt optimization", "LLM pipelines", "Research"],
    integrations: ["OpenAI", "Anthropic", "Local models"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/stanfordnlp/dspy",
    githubStars: 18000,
    websiteUrl: "https://dspy-docs.vercel.app",
    docsUrl: "https://dspy-docs.vercel.app",
    featured: false,
    lastUpdated: "2025-02-03",
    pros: ["Novel programming paradigm", "Automatic prompt optimization", "Research-backed"],
    cons: ["Steep learning curve", "Different mental model", "Smaller ecosystem"],
    setupComplexity: "Medium",
    maturity: "Early",
  },
  {
    slug: "instructor",
    name: "Instructor",
    shortDescription: "Structured outputs from LLMs with validation",
    description: "Instructor makes it easy to get structured, validated outputs from LLMs. Built on top of Pydantic, it provides a simple API for extracting typed data from LLM responses with automatic retries, streaming, and validation.",
    category: "framework",
    subcategories: ["llm-framework", "data-extraction"],
    useCases: ["Data extraction", "Structured outputs", "Form filling"],
    integrations: ["OpenAI", "Anthropic", "Mistral", "LiteLLM"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/jxnl/instructor",
    githubStars: 8000,
    websiteUrl: "https://python.useinstructor.com",
    docsUrl: "https://python.useinstructor.com",
    featured: false,
    lastUpdated: "2025-02-09",
    pros: ["Dead simple API", "Pydantic validation", "Works with any LLM"],
    cons: ["Focused on extraction only", "Python-centric", "Limited agent capabilities"],
    setupComplexity: "Low",
    maturity: "Growing",
  },

  // ── MCP Servers ───────────────────────────────────────────────────────────
  {
    slug: "mcp-github",
    name: "GitHub MCP Server",
    shortDescription: "MCP server for GitHub repository operations",
    description: "Official MCP server for GitHub that enables AI agents to interact with GitHub repositories. Supports creating issues, pull requests, searching code, managing branches, and reading repository contents through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["developer-tools", "version-control"],
    useCases: ["Repository management", "Issue tracking", "Code search"],
    integrations: ["GitHub", "Claude", "Cursor", "Windsurf"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: true,
    sponsoredTier: "basic",
    lastUpdated: "2025-02-12",
    pros: ["Official Anthropic server", "Comprehensive GitHub API coverage", "Well-documented"],
    cons: ["Requires GitHub PAT", "Rate limiting concerns", "Large response payloads"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "mcp-slack",
    name: "Slack MCP Server",
    shortDescription: "MCP server for Slack workspace interactions",
    description: "MCP server that enables AI agents to interact with Slack workspaces. Supports reading and sending messages, managing channels, searching conversations, and handling reactions through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["communication", "team-collaboration"],
    useCases: ["Message automation", "Channel management", "Conversation search"],
    integrations: ["Slack", "Claude", "Cursor"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Direct Slack API access", "Channel & thread support", "Easy setup"],
    cons: ["Requires Slack Bot Token", "Limited to text interactions", "No file handling"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "mcp-notion",
    name: "Notion MCP Server",
    shortDescription: "MCP server for Notion workspace management",
    description: "MCP server that enables AI agents to interact with Notion workspaces. Supports creating and editing pages, querying databases, managing blocks, and searching content through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["productivity", "documentation"],
    useCases: ["Content management", "Database queries", "Documentation automation"],
    integrations: ["Notion", "Claude", "Cursor"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-08",
    pros: ["Full Notion API coverage", "Database query support", "Block-level editing"],
    cons: ["Complex permission setup", "API rate limits", "Nested block limitations"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "mcp-postgres",
    name: "PostgreSQL MCP Server",
    shortDescription: "MCP server for PostgreSQL database operations",
    description: "MCP server that enables AI agents to interact with PostgreSQL databases. Supports running queries, inspecting schemas, managing data, and performing database operations through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["database", "developer-tools"],
    useCases: ["Database queries", "Schema inspection", "Data analysis"],
    integrations: ["PostgreSQL", "Claude", "Cursor", "Supabase"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-06",
    pros: ["Direct SQL execution", "Schema introspection", "Read-only mode available"],
    cons: ["Security considerations", "No ORM abstraction", "Connection management"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "mcp-filesystem",
    name: "Filesystem MCP Server",
    shortDescription: "MCP server for local filesystem operations",
    description: "Official MCP server for local filesystem access. Enables AI agents to read, write, search, and manage files on the local filesystem with configurable access controls and sandboxing.",
    category: "mcp-server",
    subcategories: ["developer-tools", "system"],
    useCases: ["File management", "Code editing", "Content generation"],
    integrations: ["Claude", "Cursor", "Windsurf"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["Sandboxed access controls", "Fast local operations", "Simple configuration"],
    cons: ["Security requires careful config", "Local only", "No cloud storage support"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "mcp-google-drive",
    name: "Google Drive MCP Server",
    shortDescription: "MCP server for Google Drive file operations",
    description: "MCP server that enables AI agents to interact with Google Drive. Supports reading, creating, and searching files, managing permissions, and accessing Google Docs, Sheets, and Slides through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["productivity", "cloud-storage"],
    useCases: ["Document management", "File search", "Content extraction"],
    integrations: ["Google Drive", "Google Docs", "Claude", "Cursor"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-01-25",
    pros: ["Full Google Drive API access", "Multi-format support", "Permission management"],
    cons: ["OAuth setup complexity", "API quotas", "Limited real-time sync"],
    setupComplexity: "Medium",
    maturity: "Early",
  },
  {
    slug: "mcp-brave-search",
    name: "Brave Search MCP Server",
    shortDescription: "MCP server for web search via Brave Search API",
    description: "MCP server that enables AI agents to perform web searches using the Brave Search API. Provides real-time web search results, local search, and news search through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["search", "web"],
    useCases: ["Web research", "Fact checking", "News monitoring"],
    integrations: ["Brave Search", "Claude", "Cursor"],
    pricingModel: "Free",
    websiteUrl: "https://modelcontextprotocol.io",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    featured: false,
    lastUpdated: "2025-02-01",
    pros: ["Privacy-focused search", "Fast results", "Local search support"],
    cons: ["Requires Brave API key", "Limited advanced operators", "Smaller index than Google"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "mcp-puppeteer",
    name: "Puppeteer MCP Server",
    shortDescription: "MCP server for browser automation via Puppeteer",
    description: "MCP server that enables AI agents to control a web browser through Puppeteer. Supports page navigation, element interaction, screenshots, PDF generation, and web scraping through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["automation", "web"],
    useCases: ["Web scraping", "Browser automation", "Screenshot capture"],
    integrations: ["Puppeteer", "Chrome", "Claude", "Cursor"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-01-30",
    pros: ["Full browser control", "Screenshot & PDF support", "JavaScript execution"],
    cons: ["Resource intensive", "Headless browser setup", "Complex for simple tasks"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "mcp-memory",
    name: "Memory MCP Server",
    shortDescription: "MCP server for persistent knowledge graph memory",
    description: "MCP server that provides AI agents with persistent memory through a knowledge graph. Stores entities, relationships, and observations that persist across conversations, enabling long-term context awareness.",
    category: "mcp-server",
    subcategories: ["memory", "knowledge-graph"],
    useCases: ["Long-term memory", "Context persistence", "Knowledge management"],
    integrations: ["Claude", "Cursor", "Windsurf"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-05",
    pros: ["Persistent across sessions", "Knowledge graph structure", "Simple entity model"],
    cons: ["Local file storage only", "No vector search", "Manual entity management"],
    setupComplexity: "Low",
    maturity: "Early",
  },
  {
    slug: "mcp-sqlite",
    name: "SQLite MCP Server",
    shortDescription: "MCP server for SQLite database operations",
    description: "MCP server that enables AI agents to interact with SQLite databases. Supports creating tables, running queries, analyzing data, and managing local databases through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["database", "developer-tools"],
    useCases: ["Local data analysis", "Prototyping", "Data management"],
    integrations: ["SQLite", "Claude", "Cursor"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-03",
    pros: ["Zero configuration", "No server required", "Great for prototyping"],
    cons: ["Single-file database", "No concurrent writes", "Limited scalability"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "mcp-sentry",
    name: "Sentry MCP Server",
    shortDescription: "MCP server for Sentry error tracking integration",
    description: "MCP server that enables AI agents to interact with Sentry for error tracking and monitoring. Supports querying issues, analyzing error trends, and managing alerts through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["monitoring", "developer-tools"],
    useCases: ["Error analysis", "Bug triage", "Performance monitoring"],
    integrations: ["Sentry", "Claude", "Cursor"],
    pricingModel: "Open Source",
    websiteUrl: "https://sentry.io",
    featured: false,
    lastUpdated: "2025-01-20",
    pros: ["Direct error access", "Issue trend analysis", "Alert management"],
    cons: ["Requires Sentry account", "Limited to Sentry data", "API rate limits"],
    setupComplexity: "Medium",
    maturity: "Early",
  },
  {
    slug: "mcp-linear",
    name: "Linear MCP Server",
    shortDescription: "MCP server for Linear project management",
    description: "MCP server that enables AI agents to interact with Linear for project management. Supports creating and managing issues, viewing project status, and automating workflows through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["project-management", "developer-tools"],
    useCases: ["Issue management", "Sprint planning", "Workflow automation"],
    integrations: ["Linear", "Claude", "Cursor"],
    pricingModel: "Open Source",
    websiteUrl: "https://linear.app",
    featured: false,
    lastUpdated: "2025-01-28",
    pros: ["Clean Linear API integration", "Issue lifecycle management", "Team workflow support"],
    cons: ["Linear-specific", "Limited reporting", "Requires API key setup"],
    setupComplexity: "Low",
    maturity: "Early",
  },
  {
    slug: "mcp-fetch",
    name: "Fetch MCP Server",
    shortDescription: "MCP server for fetching and converting web content",
    description: "MCP server that enables AI agents to fetch URLs and convert web pages to markdown for easy consumption. Supports HTML to markdown conversion, robots.txt checking, and content extraction.",
    category: "mcp-server",
    subcategories: ["web", "content"],
    useCases: ["Web content reading", "Documentation fetching", "Content extraction"],
    integrations: ["Claude", "Cursor", "Windsurf"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    websiteUrl: "https://modelcontextprotocol.io",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Simple URL fetching", "Markdown conversion", "Robots.txt compliance"],
    cons: ["No JavaScript rendering", "Limited to public URLs", "Basic content extraction"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "mcp-google-maps",
    name: "Google Maps MCP Server",
    shortDescription: "MCP server for Google Maps location services",
    description: "MCP server that enables AI agents to access Google Maps APIs for geocoding, place search, directions, and location-based services through the Model Context Protocol.",
    category: "mcp-server",
    subcategories: ["location", "maps"],
    useCases: ["Geocoding", "Place search", "Route planning"],
    integrations: ["Google Maps", "Claude", "Cursor"],
    pricingModel: "Free",
    websiteUrl: "https://modelcontextprotocol.io",
    githubUrl: "https://github.com/modelcontextprotocol/servers",
    githubStars: 12000,
    featured: false,
    lastUpdated: "2025-01-15",
    pros: ["Comprehensive location data", "Geocoding support", "Place details"],
    cons: ["Requires Google API key", "Usage costs at scale", "Rate limiting"],
    setupComplexity: "Medium",
    maturity: "Early",
  },

  // ── Infrastructure ────────────────────────────────────────────────────────
  {
    slug: "pinecone",
    name: "Pinecone",
    shortDescription: "Managed vector database for AI applications",
    description: "Pinecone is a fully managed vector database that makes it easy to build high-performance vector search applications. It handles the infrastructure for storing and querying high-dimensional vectors, with features like metadata filtering, namespaces, and serverless scaling.",
    category: "infra",
    subcategories: ["vector-database", "managed-service"],
    useCases: ["Semantic search", "RAG systems", "Recommendation engines"],
    integrations: ["LangChain", "LlamaIndex", "OpenAI", "Haystack"],
    pricingModel: "Freemium",
    pricing: "Free tier, Starter $70/mo, Enterprise custom",
    websiteUrl: "https://pinecone.io",
    docsUrl: "https://docs.pinecone.io",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Fully managed & serverless", "Fast query performance", "Easy to get started"],
    cons: ["Vendor lock-in", "Costs at scale", "Limited query capabilities vs SQL"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "weaviate",
    name: "Weaviate",
    shortDescription: "Open-source vector database with built-in ML models",
    description: "Weaviate is an open-source vector database that stores data objects and vector embeddings. It supports semantic search, hybrid search (vector + keyword), and generative search. Includes built-in vectorization modules and can run self-hosted or as a managed cloud service.",
    category: "infra",
    subcategories: ["vector-database", "open-source"],
    useCases: ["Semantic search", "Hybrid search", "Generative search"],
    integrations: ["LangChain", "LlamaIndex", "OpenAI", "HuggingFace", "Cohere"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/weaviate/weaviate",
    githubStars: 12000,
    websiteUrl: "https://weaviate.io",
    docsUrl: "https://weaviate.io/developers/weaviate",
    featured: false,
    lastUpdated: "2025-02-08",
    pros: ["Open source with cloud option", "Built-in vectorizers", "Hybrid search"],
    cons: ["Resource intensive self-hosted", "Complex schema management", "Learning curve"],
    setupComplexity: "Medium",
    maturity: "Mature",
  },
  {
    slug: "chromadb",
    name: "ChromaDB",
    shortDescription: "Open-source embedding database for AI applications",
    description: "ChromaDB is the AI-native open-source embedding database. It's designed to make it easy to build LLM applications by storing and retrieving embeddings. Simple to use, runs in-process or as a server, with a focus on developer experience.",
    category: "infra",
    subcategories: ["vector-database", "open-source"],
    useCases: ["RAG applications", "Embedding storage", "Similarity search"],
    integrations: ["LangChain", "LlamaIndex", "OpenAI"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/chroma-core/chroma",
    githubStars: 15000,
    websiteUrl: "https://trychroma.com",
    docsUrl: "https://docs.trychroma.com",
    featured: false,
    lastUpdated: "2025-02-06",
    pros: ["Dead simple API", "Runs in-process", "Great for prototyping"],
    cons: ["Not as performant at scale", "Limited filtering", "Fewer features than Pinecone"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "qdrant",
    name: "Qdrant",
    shortDescription: "High-performance open-source vector search engine",
    description: "Qdrant is a vector similarity search engine and database written in Rust. It provides production-ready service with filtering, payloads, and distributed deployment. Known for excellent performance, rich filtering capabilities, and operational simplicity.",
    category: "infra",
    subcategories: ["vector-database", "search-engine"],
    useCases: ["Vector search at scale", "Recommendation systems", "Anomaly detection"],
    integrations: ["LangChain", "LlamaIndex", "Haystack", "OpenAI"],
    pricingModel: "Open Source",
    githubUrl: "https://github.com/qdrant/qdrant",
    githubStars: 21000,
    websiteUrl: "https://qdrant.tech",
    docsUrl: "https://qdrant.tech/documentation/",
    featured: false,
    lastUpdated: "2025-02-09",
    pros: ["Rust-powered performance", "Rich filtering", "Good documentation"],
    cons: ["Smaller community", "Self-hosting complexity", "Fewer integrations"],
    setupComplexity: "Medium",
    maturity: "Growing",
  },
  {
    slug: "modal",
    name: "Modal",
    shortDescription: "Serverless cloud for AI/ML workloads",
    description: "Modal is a serverless cloud platform optimized for AI and ML workloads. Run any code on the cloud with zero infrastructure, including GPU workloads. Features include container-based functions, scheduled jobs, web endpoints, and seamless local-to-cloud development.",
    category: "infra",
    subcategories: ["compute", "serverless"],
    useCases: ["ML model serving", "GPU compute", "Data processing"],
    integrations: ["PyTorch", "TensorFlow", "HuggingFace", "FastAPI"],
    pricingModel: "Freemium",
    pricing: "Pay per compute second, free tier available",
    websiteUrl: "https://modal.com",
    docsUrl: "https://modal.com/docs",
    featured: false,
    lastUpdated: "2025-02-11",
    pros: ["Zero infrastructure", "GPU access", "Fast cold starts"],
    cons: ["Python only", "Vendor lock-in", "Debugging can be tricky"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "replicate",
    name: "Replicate",
    shortDescription: "Run and deploy ML models with a simple API",
    description: "Replicate makes it easy to run machine learning models in the cloud with a simple API. It hosts thousands of open-source models that you can run with a few lines of code. Also supports custom model deployment via Cog.",
    category: "infra",
    subcategories: ["model-serving", "api"],
    useCases: ["Model inference", "Image generation", "Audio processing"],
    integrations: ["Stable Diffusion", "Llama", "Whisper", "Python", "Node.js"],
    pricingModel: "Freemium",
    pricing: "Pay per prediction, varies by model",
    websiteUrl: "https://replicate.com",
    docsUrl: "https://replicate.com/docs",
    featured: false,
    lastUpdated: "2025-02-07",
    pros: ["Thousands of models", "Simple API", "No GPU management"],
    cons: ["Cold start latency", "Per-prediction costs", "Limited customization"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "groq",
    name: "Groq",
    shortDescription: "Fastest AI inference with custom LPU hardware",
    description: "Groq provides the fastest AI inference available, powered by their custom Language Processing Unit (LPU). Offers API access to popular open-source models like Llama and Mixtral with sub-second latency and extremely high throughput.",
    category: "infra",
    subcategories: ["inference", "hardware"],
    useCases: ["Real-time AI", "High-throughput inference", "Low-latency applications"],
    integrations: ["Llama", "Mixtral", "Gemma", "LangChain", "Vercel AI SDK"],
    pricingModel: "Freemium",
    pricing: "Free tier, pay-per-token at scale",
    websiteUrl: "https://groq.com",
    docsUrl: "https://console.groq.com/docs",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["Fastest inference available", "Competitive pricing", "Simple API"],
    cons: ["Limited model selection", "Capacity constraints", "No fine-tuning"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "helicone",
    name: "Helicone",
    shortDescription: "Open-source LLM observability and monitoring platform",
    description: "Helicone is an open-source observability platform for LLM applications. It provides request logging, cost tracking, latency monitoring, caching, rate limiting, and analytics with a single line of code change.",
    category: "infra",
    subcategories: ["observability", "monitoring"],
    useCases: ["LLM cost tracking", "Request monitoring", "Performance analytics"],
    integrations: ["OpenAI", "Anthropic", "Azure", "LangChain"],
    pricingModel: "Freemium",
    pricing: "Free up to 100K requests/mo",
    githubUrl: "https://github.com/Helicone/helicone",
    githubStars: 2000,
    websiteUrl: "https://helicone.ai",
    docsUrl: "https://docs.helicone.ai",
    featured: false,
    lastUpdated: "2025-02-05",
    pros: ["One-line integration", "Cost tracking", "Open source option"],
    cons: ["Proxy-based architecture", "Free tier limits", "Limited custom dashboards"],
    setupComplexity: "Low",
    maturity: "Growing",
  },

  // ── Platforms ──────────────────────────────────────────────────────────────
  {
    slug: "openai-platform",
    name: "OpenAI Platform",
    shortDescription: "The leading AI platform with GPT-4, DALL-E, and Assistants API",
    description: "OpenAI Platform provides API access to the most advanced AI models including GPT-4, GPT-4 Turbo, DALL-E 3, and Whisper. The Assistants API enables building AI assistants with tools, retrieval, and code execution capabilities.",
    category: "platform",
    subcategories: ["llm-provider", "api"],
    useCases: ["Text generation", "Code generation", "Image generation", "AI assistants"],
    integrations: ["LangChain", "LlamaIndex", "Vercel AI SDK", "Every major framework"],
    pricingModel: "Paid",
    pricing: "Pay per token, varies by model",
    websiteUrl: "https://platform.openai.com",
    docsUrl: "https://platform.openai.com/docs",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["Most advanced models", "Massive ecosystem", "Comprehensive API"],
    cons: ["Expensive at scale", "Closed source models", "Rate limits"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "anthropic",
    name: "Anthropic (Claude)",
    shortDescription: "AI safety company behind Claude — best for coding and analysis",
    description: "Anthropic builds reliable, interpretable AI systems. Their Claude family of models excels at coding, analysis, and complex reasoning. Known for large context windows (200K tokens), tool use capabilities, and the Model Context Protocol (MCP).",
    category: "platform",
    subcategories: ["llm-provider", "api"],
    useCases: ["Code generation", "Analysis", "Long-form writing", "Tool use"],
    integrations: ["LangChain", "LlamaIndex", "Vercel AI SDK", "MCP"],
    pricingModel: "Paid",
    pricing: "Pay per token, varies by model",
    websiteUrl: "https://anthropic.com",
    docsUrl: "https://docs.anthropic.com",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["Excellent at coding", "200K context window", "MCP ecosystem"],
    cons: ["Premium pricing", "Fewer model tiers", "Limited image generation"],
    setupComplexity: "Low",
    maturity: "Mature",
  },
  {
    slug: "google-ai",
    name: "Google AI (Gemini)",
    shortDescription: "Google's multimodal AI platform with Gemini models",
    description: "Google AI provides access to the Gemini family of multimodal models that can understand text, images, video, and audio. Includes Gemini Pro, Gemini Ultra, and the free Gemini API, plus integration with Google Cloud's AI infrastructure.",
    category: "platform",
    subcategories: ["llm-provider", "multimodal"],
    useCases: ["Multimodal AI", "Content understanding", "Code generation"],
    integrations: ["LangChain", "LlamaIndex", "Vercel AI SDK", "Google Cloud"],
    pricingModel: "Freemium",
    pricing: "Free tier available, pay per token at scale",
    websiteUrl: "https://ai.google.dev",
    docsUrl: "https://ai.google.dev/docs",
    featured: false,
    lastUpdated: "2025-02-12",
    pros: ["True multimodal support", "Competitive pricing", "Google ecosystem"],
    cons: ["API stability concerns", "Availability varies by region", "Fewer third-party integrations"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "mistral",
    name: "Mistral AI",
    shortDescription: "European AI lab with open and commercial frontier models",
    description: "Mistral AI develops both open-source and commercial LLMs. Known for efficient models like Mixtral (mixture of experts) and Mistral Large. Popular for self-hosting and for developers who want a strong alternative to OpenAI/Anthropic.",
    category: "platform",
    subcategories: ["llm-provider", "open-source"],
    useCases: ["Text generation", "Code assistance", "Self-hosted LLMs"],
    integrations: ["LangChain", "LlamaIndex", "Ollama", "vLLM"],
    pricingModel: "Freemium",
    pricing: "Open models free, API pricing varies",
    websiteUrl: "https://mistral.ai",
    docsUrl: "https://docs.mistral.ai",
    featured: false,
    lastUpdated: "2025-02-08",
    pros: ["Efficient open models", "Strong European data compliance", "Self-hosting option"],
    cons: ["Smaller model selection", "Less mature API", "Fewer enterprise features"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "together-ai",
    name: "Together AI",
    shortDescription: "Fast inference platform for open-source AI models",
    description: "Together AI provides a cloud platform for running, fine-tuning, and training open-source AI models. Known for fast inference, competitive pricing, and support for a wide range of open models including Llama, Mixtral, and more.",
    category: "infra",
    subcategories: ["inference", "fine-tuning"],
    useCases: ["Model inference", "Fine-tuning", "Custom training"],
    integrations: ["Llama", "Mixtral", "LangChain", "OpenAI-compatible API"],
    pricingModel: "Paid",
    pricing: "Pay per token, competitive pricing",
    websiteUrl: "https://together.ai",
    docsUrl: "https://docs.together.ai",
    featured: false,
    lastUpdated: "2025-02-06",
    pros: ["Fast inference", "Wide model selection", "Fine-tuning support"],
    cons: ["Open models only", "Variable availability", "Complex pricing tiers"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "fireworks-ai",
    name: "Fireworks AI",
    shortDescription: "Fastest generative AI inference platform",
    description: "Fireworks AI provides the fastest inference for generative AI models with production-grade reliability. Supports function calling, JSON mode, and custom model deployment. Known for sub-200ms latency on popular open models.",
    category: "infra",
    subcategories: ["inference", "api"],
    useCases: ["Low-latency inference", "Function calling", "Production AI"],
    integrations: ["Llama", "Mixtral", "LangChain", "OpenAI-compatible API"],
    pricingModel: "Freemium",
    pricing: "Free tier, pay per token",
    websiteUrl: "https://fireworks.ai",
    docsUrl: "https://docs.fireworks.ai",
    featured: false,
    lastUpdated: "2025-02-04",
    pros: ["Sub-200ms latency", "Function calling support", "OpenAI-compatible"],
    cons: ["Limited model selection", "Newer platform", "Less documentation"],
    setupComplexity: "Low",
    maturity: "Growing",
  },
  {
    slug: "weights-biases",
    name: "Weights & Biases",
    shortDescription: "ML experiment tracking, model management, and MLOps platform",
    description: "Weights & Biases (W&B) is the leading ML experiment tracking platform. It provides tools for experiment logging, dataset versioning, model management, hyperparameter sweeps, and collaborative ML development.",
    category: "infra",
    subcategories: ["mlops", "experiment-tracking"],
    useCases: ["Experiment tracking", "Model management", "Team collaboration"],
    integrations: ["PyTorch", "TensorFlow", "HuggingFace", "Lightning"],
    pricingModel: "Freemium",
    pricing: "Free for individuals, Teams $50/user/mo",
    websiteUrl: "https://wandb.ai",
    docsUrl: "https://docs.wandb.ai",
    featured: false,
    lastUpdated: "2025-02-10",
    pros: ["Industry standard for tracking", "Beautiful visualizations", "Strong integrations"],
    cons: ["Can be complex to set up", "Costs for teams", "Heavy for simple projects"],
    setupComplexity: "Medium",
    maturity: "Mature",
  },
];
